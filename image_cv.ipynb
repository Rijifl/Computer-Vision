{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Settings\n",
    "INPUT_FOLDER = \"path/to/your/images\"  # CHANGE THIS\n",
    "OUTPUT_FOLDER = \"output_balanced\"     # CHANGE THIS\n",
    "IMAGE_SIZE = 224\n",
    "TARGET_COUNT = 30  # Target images per class\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a82b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Clear output folders\n",
    "import shutil\n",
    "\n",
    "# Define folders to clear\n",
    "folders_to_clear = [\n",
    "    f\"{OUTPUT_FOLDER}/augmented\",\n",
    "    f\"{OUTPUT_FOLDER}/resized\", \n",
    "    f\"{OUTPUT_FOLDER}/final\"\n",
    "]\n",
    "\n",
    "# Clear each folder\n",
    "print(\"Clearing output folders...\")\n",
    "for folder in folders_to_clear:\n",
    "    if os.path.exists(folder):\n",
    "        # Remove all contents\n",
    "        shutil.rmtree(folder)\n",
    "        # Recreate empty folder\n",
    "        os.makedirs(folder)\n",
    "        print(f\"  ✓ Cleared: {folder}\")\n",
    "    else:\n",
    "        # Create if doesn't exist\n",
    "        os.makedirs(folder)\n",
    "        print(f\"  ✓ Created: {folder}\")\n",
    "\n",
    "print(\"\\nAll output folders cleared and ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbdf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create folders\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/augmented\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/resized\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/final\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f612e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Basic functions\n",
    "def get_class_label(filename):\n",
    "    \"\"\"Get class from filename (e.g., '0p', '5p', '100p')\"\"\"\n",
    "    match = re.search(r'(\\d+)[pP]', filename)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}p\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def get_numeric_label(filename):\n",
    "    \"\"\"Extract numeric value from filename for regression\"\"\"\n",
    "    match = re.search(r'(\\d+)[pP]', filename)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return 0.0\n",
    "\n",
    "def make_square(image, size):\n",
    "    \"\"\"Resize image and pad to square while keeping RGB\"\"\"\n",
    "    # Convert to RGB if not already\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    # Calculate new size\n",
    "    w, h = image.size\n",
    "    scale = size / max(w, h)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "    \n",
    "    # Resize\n",
    "    resized = image.resize((new_w, new_h), Image.BILINEAR)\n",
    "    \n",
    "    # Create square with white background\n",
    "    square = Image.new('RGB', (size, size), (255, 255, 255))\n",
    "    \n",
    "    # Paste in center\n",
    "    x = (size - new_w) // 2\n",
    "    y = (size - new_h) // 2\n",
    "    square.paste(resized, (x, y))\n",
    "    \n",
    "    return square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27314d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define augmentations\n",
    "def aug1(img): return img.rotate(90, expand=True)     # 90° rotation\n",
    "def aug2(img): return img.rotate(180, expand=True)    # 180° rotation  \n",
    "def aug3(img): return img.rotate(270, expand=True)    # 270° rotation\n",
    "def aug4(img): return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "def aug5(img): return img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "augmentation_list = [aug1, aug2, aug3, aug4, aug5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535dd671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Group images by class\n",
    "image_files = [f for f in os.listdir(INPUT_FOLDER) \n",
    "               if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp'))]\n",
    "\n",
    "# Group by class\n",
    "classes = {}\n",
    "for filename in image_files:\n",
    "    label = get_class_label(filename)\n",
    "    if label not in classes:\n",
    "        classes[label] = []\n",
    "    classes[label].append(filename)\n",
    "\n",
    "# Show counts\n",
    "print(\"Images per class:\")\n",
    "for label, images in sorted(classes.items()):\n",
    "    print(f\"  {label}: {len(images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53802e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Copy originals and create augmentations\n",
    "print(\"\\nProcessing images...\")\n",
    "\n",
    "for class_label, filenames in sorted(classes.items()):\n",
    "    print(f\"\\nClass {class_label}:\")\n",
    "    \n",
    "    # Copy all originals first\n",
    "    for filename in filenames:\n",
    "        img = Image.open(os.path.join(INPUT_FOLDER, filename))\n",
    "        # Keep as RGB (no binary conversion)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        base = os.path.splitext(filename)[0]\n",
    "        img.save(f\"{OUTPUT_FOLDER}/augmented/{base}_original.jpg\")\n",
    "    \n",
    "    # Create augmentations if needed\n",
    "    current_count = len(filenames)\n",
    "    if current_count < TARGET_COUNT:\n",
    "        needed = TARGET_COUNT - current_count\n",
    "        print(f\"  Creating {needed} augmentations...\")\n",
    "        \n",
    "        for i in range(needed):\n",
    "            # Pick random original\n",
    "            source_file = random.choice(filenames)\n",
    "            img = Image.open(os.path.join(INPUT_FOLDER, source_file))\n",
    "            # Keep as RGB (no binary conversion)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Apply 3-4 random augmentations\n",
    "            num_augs = random.randint(3, 4)\n",
    "            selected_augs = random.sample(augmentation_list, num_augs)\n",
    "            \n",
    "            augmented = img\n",
    "            for aug_func in selected_augs:\n",
    "                augmented = aug_func(augmented)\n",
    "            \n",
    "            # Save\n",
    "            base = os.path.splitext(source_file)[0]\n",
    "            augmented.save(f\"{OUTPUT_FOLDER}/augmented/{base}_aug{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Resize all images\n",
    "print(\"\\nResizing all images...\")\n",
    "augmented_files = [f for f in os.listdir(f\"{OUTPUT_FOLDER}/augmented\") \n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "for i, filename in enumerate(augmented_files):\n",
    "    if i % 50 == 0:\n",
    "        print(f\"  {i}/{len(augmented_files)}\")\n",
    "    \n",
    "    img = Image.open(f\"{OUTPUT_FOLDER}/augmented/{filename}\")\n",
    "    resized = make_square(img, IMAGE_SIZE)\n",
    "    \n",
    "    # Save as JPG to maintain RGB\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    resized.save(f\"{OUTPUT_FOLDER}/resized/{base}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c326a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Normalize for ResNet (ImageNet normalization)\n",
    "print(\"\\nNormalizing images for ResNet...\")\n",
    "resized_files = [f for f in os.listdir(f\"{OUTPUT_FOLDER}/resized\") \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# ImageNet normalization values for ResNet\n",
    "normalize = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "for i, filename in enumerate(resized_files):\n",
    "    if i % 50 == 0:\n",
    "        print(f\"  {i}/{len(resized_files)}\")\n",
    "    \n",
    "    # Load RGB image\n",
    "    img = Image.open(f\"{OUTPUT_FOLDER}/resized/{filename}\")\n",
    "    \n",
    "    # Apply ResNet normalization\n",
    "    tensor = normalize(img)\n",
    "    \n",
    "    # Save tensor\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    np.save(f\"{OUTPUT_FOLDER}/final/{base}.npy\", tensor.numpy())\n",
    "    \n",
    "    # Save image for viewing\n",
    "    img.save(f\"{OUTPUT_FOLDER}/final/{base}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a200261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Check final counts\n",
    "print(\"\\nFinal image count per class:\")\n",
    "final_counts = {}\n",
    "for filename in os.listdir(f\"{OUTPUT_FOLDER}/final\"):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        label = get_class_label(filename)\n",
    "        final_counts[label] = final_counts.get(label, 0) + 1\n",
    "\n",
    "for label, count in sorted(final_counts.items()):\n",
    "    print(f\"  {label}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: ResNet Regression Model\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "class ResNetRegression(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNetRegression, self).__init__()\n",
    "        # Load pretrained ResNet18\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Replace the final classification layer with regression layer\n",
    "        # ResNet18 has 512 features before the final layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.resnet.fc.in_features, 1)  # Single output for regression\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetRegression(pretrained=True).to(device)\n",
    "\n",
    "print(f\"Model created and moved to {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"ResNet regression model ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Data Loading and Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CoinDataset(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all .npy files (normalized tensors)\n",
    "        self.files = [f for f in os.listdir(data_folder) if f.endswith('.npy')]\n",
    "        \n",
    "        # Extract labels (numeric values for regression)\n",
    "        self.labels = []\n",
    "        for filename in self.files:\n",
    "            label = get_numeric_label(filename)\n",
    "            self.labels.append(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load normalized tensor\n",
    "        tensor_path = os.path.join(self.data_folder, self.files[idx])\n",
    "        tensor = torch.from_numpy(np.load(tensor_path)).float()\n",
    "        \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        \n",
    "        return tensor, label\n",
    "\n",
    "# Create dataset\n",
    "final_folder = f\"{OUTPUT_FOLDER}/final\"\n",
    "full_dataset = CoinDataset(final_folder)\n",
    "\n",
    "print(f\"Total samples: {len(full_dataset)}\")\n",
    "print(f\"Sample tensor shape: {full_dataset[0][0].shape}\")\n",
    "print(f\"Sample label: {full_dataset[0][1]}\")\n",
    "\n",
    "# Split into train/validation (80/20 split)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# Use a subset for training (10% of total data for quick training)\n",
    "subset_size = max(100, len(full_dataset) // 10)  # At least 100 samples\n",
    "subset_train_size = int(0.8 * subset_size)\n",
    "subset_val_size = subset_size - subset_train_size\n",
    "\n",
    "print(f\"Using subset of {subset_size} samples for training\")\n",
    "print(f\"Training samples: {subset_train_size}\")\n",
    "print(f\"Validation samples: {subset_val_size}\")\n",
    "\n",
    "# Create subset indices\n",
    "indices = list(range(len(full_dataset)))\n",
    "np.random.shuffle(indices)\n",
    "subset_indices = indices[:subset_size]\n",
    "\n",
    "train_indices = subset_indices[:subset_train_size]\n",
    "val_indices = subset_indices[subset_train_size:]\n",
    "\n",
    "# Create samplers\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(full_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(full_dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "print(f\"Data loaders created with batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Training Loop with MSE, MAE, and R² tracking\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data).squeeze()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        all_preds.extend(output.detach().cpu().numpy())\n",
    "        all_targets.extend(target.detach().cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "    \n",
    "    return avg_loss, mae, r2\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data).squeeze()\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            all_preds.extend(output.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "    \n",
    "    return avg_loss, mae, r2\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Storage for metrics\n",
    "history = defaultdict(list)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_mae, train_r2 = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_mae, val_r2 = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Store metrics\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['train_r2'].append(train_r2)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    history['val_r2'].append(val_r2)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{OUTPUT_FOLDER}/best_model.pth')\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1:2d}/{num_epochs}\")\n",
    "    print(f\"  Train - Loss: {train_loss:.4f}, MAE: {train_mae:.2f}, R²: {train_r2:.3f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.4f}, MAE: {val_mae:.2f}, R²: {val_r2:.3f}\")\n",
    "    print(f\"  Time: {epoch_time:.1f}s\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time:.1f}s\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Final results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final Train - Loss: {history['train_loss'][-1]:.4f}, MAE: {history['train_mae'][-1]:.2f}, R²: {history['train_r2'][-1]:.3f}\")\n",
    "print(f\"Final Val   - Loss: {history['val_loss'][-1]:.4f}, MAE: {history['val_mae'][-1]:.2f}, R²: {history['val_r2'][-1]:.3f}\")\n",
    "print(f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "print(f\"Model saved to: {OUTPUT_FOLDER}/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332caa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Plot Training Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training metrics\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_title('MSE Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # MAE plot\n",
    "    axes[1].plot(history['train_mae'], label='Train MAE', marker='o')\n",
    "    axes[1].plot(history['val_mae'], label='Val MAE', marker='s')\n",
    "    axes[1].set_title('Mean Absolute Error')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # R² plot\n",
    "    axes[2].plot(history['train_r2'], label='Train R²', marker='o')\n",
    "    axes[2].plot(history['val_r2'], label='Val R²', marker='s')\n",
    "    axes[2].set_title('R² Score')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('R²')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_FOLDER}/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot results if history exists\n",
    "try:\n",
    "    plot_training_history(history)\n",
    "    print(f\"Training plots saved to {OUTPUT_FOLDER}/training_history.png\")\n",
    "except NameError:\n",
    "    print(\"Run the training cell first to generate history data\")\n",
    "\n",
    "# Quick model test\n",
    "def test_model_prediction():\n",
    "    \"\"\"Test the model on a few samples\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get a batch from validation\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            predictions = model(data).squeeze()\n",
    "            \n",
    "            print(\"\\nSample Predictions vs Actual:\")\n",
    "            print(\"-\" * 40)\n",
    "            for i in range(min(5, len(predictions))):\n",
    "                pred = predictions[i].cpu().item()\n",
    "                actual = target[i].cpu().item()\n",
    "                error = abs(pred - actual)\n",
    "                print(f\"Predicted: {pred:6.2f} | Actual: {actual:6.2f} | Error: {error:5.2f}\")\n",
    "            break\n",
    "\n",
    "try:\n",
    "    test_model_prediction()\n",
    "except:\n",
    "    print(\"Train the model first to see predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
