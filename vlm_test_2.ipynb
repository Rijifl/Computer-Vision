{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a03c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Qwen3-VL-30B-A3B-Instruct-FP8\n",
    "# Requires vLLM for efficient inference with FP8 quantized model\n",
    "# !pip install vllm\n",
    "# !pip install qwen-vl-utils>=0.0.14\n",
    "# !pip install transformers\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "print(\"⚠️ Make sure you have installed: vllm, qwen-vl-utils>=0.0.14, transformers\")\n",
    "print(\"⚠️ This model requires significant GPU memory (30B FP8 quantized)\")\n",
    "print(\"⚠️ Multiple GPUs recommended - will use tensor parallelism across all available GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# Set multiprocessing method for vLLM\n",
    "os.environ['VLLM_WORKER_MULTIPROC_METHOD'] = 'spawn'\n",
    "\n",
    "# Model checkpoint path\n",
    "MODEL_PATH = \"Qwen/Qwen3-VL-30B-A3B-Instruct-FP8\"\n",
    "\n",
    "# Load processor with high resolution settings for better face recognition\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    min_pixels=512 * 28 * 28,  # Increased for better face detail\n",
    "    max_pixels=2048 * 28 * 28  # Higher resolution for enhanced celebrity recognition\n",
    ")\n",
    "\n",
    "# Initialize vLLM engine for efficient inference\n",
    "# FP8 quantization provides near-BF16 performance with better efficiency\n",
    "llm = LLM(\n",
    "    model=MODEL_PATH,\n",
    "    trust_remote_code=True,\n",
    "    gpu_memory_utilization=0.70,\n",
    "    enforce_eager=False,\n",
    "    tensor_parallel_size=torch.cuda.device_count(),\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "print(\"✓ Qwen3-VL-30B-A3B-Instruct-FP8 Model loaded with vLLM!\")\n",
    "print(\"✓ FP8 quantization: Near-BF16 performance with improved efficiency\")\n",
    "print(\"✓ Enhanced features: Superior visual recognition, 256K context, celebrity recognition\")\n",
    "print(f\"✓ Resolution settings: min_pixels={512 * 28 * 28}, max_pixels={2048 * 28 * 28}\")\n",
    "print(f\"✓ Using {torch.cuda.device_count()} GPU(s) with tensor parallelism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "video_folder = \"raw_videos\"  # UPDATE THIS\n",
    "transcript_folder = \"transcript_from_audio\"  # Transcripts folder\n",
    "output_folder = \"results_qwen3vl_30b\"  # Output folder for Qwen3-VL-30B results\n",
    "\n",
    "# FPS setting for video processing\n",
    "VIDEO_FPS = 2.0  # Process 2 frames per second for thorough analysis\n",
    "\n",
    "# Sampling parameters optimized for Qwen3-VL\n",
    "SAMPLING_PARAMS = SamplingParams(\n",
    "    temperature=0.7,  # VL task optimized temperature\n",
    "    max_tokens=1024,\n",
    "    top_k=20,\n",
    "    top_p=0.8,\n",
    "    stop_token_ids=[]\n",
    ")\n",
    "\n",
    "# Single comprehensive prompt optimized for Qwen3-VL's enhanced capabilities\n",
    "comprehensive_prompt = \"\"\"Analyze this video and transcript to answer each question specifically and directly.\n",
    "\n",
    "**ANALYSIS TASKS:**\n",
    "\n",
    "1. CELEBRITIES\n",
    "List any celebrities or public figures visible. Format: [Name] - [context/role in video]\n",
    "If none, respond: \"None identified\"\n",
    "\n",
    "2. PEOPLE COUNT\n",
    "Exact number of distinct individuals visible in video: [NUMBER]\n",
    "If crowd/unclear, provide: [approximate range] (e.g., \"~15-20 people\")\n",
    "\n",
    "3. GENDER\n",
    "List each person's apparent gender presentation:\n",
    "Person 1: [Male/Female/Not clearly visible]\n",
    "Person 2: [Male/Female/Not clearly visible]\n",
    "Format: [Person number/identifier]: [Gender]\n",
    "\n",
    "4. ETHNICITY\n",
    "Describe observed ethnic/racial characteristics per person:\n",
    "Person 1: [Specific observable characteristics - e.g., \"Light skin tone, blonde hair\" OR \"Dark skin tone\" OR \"East Asian appearance\"]\n",
    "Person 2: [Observable characteristics]\n",
    "Use descriptive physical traits, not demographic labels.\n",
    "\n",
    "5. ACTIVITIES\n",
    "List all visible activities/sports:\n",
    "- [Activity 1]: [brief description]\n",
    "- [Activity 2]: [brief description]\n",
    "Include location/setting context.\n",
    "\n",
    "6. TRANSCRIPT ANALYSIS\n",
    "Main topics discussed (if transcript available):\n",
    "- Topic 1: [specific detail]\n",
    "- Topic 2: [specific detail]\n",
    "- Topic 3: [specific detail]\n",
    "Key speakers (if identifiable): [names or descriptions]\n",
    "If no transcript: \"No transcript available\"\n",
    "\n",
    "**TRANSCRIPT PROVIDED:**\n",
    "{transcript_info}\n",
    "\n",
    "**RESPONSE INSTRUCTIONS:**\n",
    "- Answer only what you observe\n",
    "- Be specific, not vague\n",
    "- Use exact numbers where possible\n",
    "- Describe visible characteristics objectively\n",
    "- Do not speculate\n",
    "- Label each answer with its number\"\"\"\n",
    "\n",
    "print(f\"Video folder: {video_folder}\")\n",
    "print(f\"Transcript folder: {transcript_folder}\")\n",
    "print(f\"Output folder: {output_folder}\")\n",
    "print(f\"Video FPS: {VIDEO_FPS}\")\n",
    "print(f\"Sampling params: temperature={SAMPLING_PARAMS.temperature}, max_tokens={SAMPLING_PARAMS.max_tokens}\")\n",
    "print(\"Using Qwen3-VL-30B-A3B-Instruct-FP8 with vLLM for efficient inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42060c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check transcript files availability\n",
    "print(\"=== TRANSCRIPT FOLDER DEBUG ===\")\n",
    "print(f\"Expected transcript folder path: {transcript_folder}\")\n",
    "if os.path.exists(transcript_folder):\n",
    "    transcript_files = [f for f in os.listdir(transcript_folder) if f.endswith('.txt')]\n",
    "    print(f\"✓ Transcript folder exists: {transcript_folder}\")\n",
    "    print(f\"Found {len(transcript_files)} .txt files:\")\n",
    "    for i, file in enumerate(transcript_files, 1):\n",
    "        file_path = os.path.join(transcript_folder, file)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "            print(f\"  {i}. {file} ({len(content)} characters)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {i}. {file} (Error reading: {e})\")\n",
    "else:\n",
    "    print(f\"Transcript folder does not exist: {transcript_folder}\")\n",
    "    print(\"Creating the folder...\")\n",
    "    os.makedirs(transcript_folder, exist_ok=True)\n",
    "    print(f\"✓ Created folder: {transcript_folder}\")\n",
    "    print(\"Please add your transcript .txt files to this folder!\")\n",
    "\n",
    "print(\"\\n=== VIDEO FOLDER DEBUG ===\")\n",
    "if os.path.exists(video_folder):\n",
    "    video_files = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    print(f\"✓ Video folder exists: {video_folder}\")\n",
    "    print(f\"Found {len(video_files)} video files:\")\n",
    "    for i, file in enumerate(video_files, 1):\n",
    "        print(f\"  {i}. {file}\")\n",
    "else:\n",
    "    print(f\"Video folder does not exist: {video_folder}\")\n",
    "    print(\"Please update the video_folder path in the settings above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96af6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load transcript for a video\n",
    "def load_transcript(video_name):\n",
    "    \"\"\"Load transcript file if it exists for the given video name.\"\"\"\n",
    "    print(f\"    Looking for transcript for video: {video_name}\")\n",
    "    \n",
    "    # Extract base name without extension for matching\n",
    "    video_base = os.path.splitext(video_name)[0]\n",
    "    \n",
    "    # Try different possible transcript filename patterns\n",
    "    possible_names = [\n",
    "        f\"{video_base}_audio_transcript.txt\",\n",
    "        f\"{video_name}_transcript.txt\",\n",
    "        f\"{video_base}_transcript.txt\",\n",
    "        f\"{video_name}.txt\",\n",
    "        f\"{video_base}.txt\"\n",
    "    ]\n",
    "    \n",
    "    # List all files in transcript folder for debugging\n",
    "    if os.path.exists(transcript_folder):\n",
    "        all_transcript_files = os.listdir(transcript_folder)\n",
    "        \n",
    "        # Try fuzzy matching - look for files that contain the video base name\n",
    "        fuzzy_matches = [f for f in all_transcript_files if video_base in f and f.endswith('.txt')]\n",
    "        if fuzzy_matches:\n",
    "            print(f\"    Fuzzy matches found: {fuzzy_matches}\")\n",
    "            possible_names.extend(fuzzy_matches)\n",
    "    else:\n",
    "        print(f\"    Transcript folder does not exist: {transcript_folder}\")\n",
    "        return None\n",
    "    \n",
    "    for transcript_name in possible_names:\n",
    "        transcript_path = os.path.join(transcript_folder, transcript_name)\n",
    "        if os.path.exists(transcript_path):\n",
    "            try:\n",
    "                with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read().strip()\n",
    "                print(f\"    ✓ Successfully loaded transcript: {transcript_name}\")\n",
    "                return content\n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Could not read transcript {transcript_name}: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Helper function to prepare inputs for vLLM\n",
    "def prepare_inputs_for_vllm(messages, processor):\n",
    "    \"\"\"Prepare inputs in vLLM format with video metadata.\"\"\"\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    # Process vision info with video metadata (requires qwen_vl_utils 0.0.14+)\n",
    "    image_inputs, video_inputs, video_kwargs = process_vision_info(\n",
    "        messages,\n",
    "        image_patch_size=processor.image_processor.patch_size,\n",
    "        return_video_kwargs=True,\n",
    "        return_video_metadata=True\n",
    "    )\n",
    "    \n",
    "    mm_data = {}\n",
    "    if image_inputs is not None:\n",
    "        mm_data['image'] = image_inputs\n",
    "    if video_inputs is not None:\n",
    "        mm_data['video'] = video_inputs\n",
    "    \n",
    "    return {\n",
    "        'prompt': text,\n",
    "        'multi_modal_data': mm_data,\n",
    "        'mm_processor_kwargs': video_kwargs\n",
    "    }\n",
    "\n",
    "# Enhanced analysis function using Qwen3-VL-30B with vLLM\n",
    "def analyze_video_with_qwen3vl(video_path, video_name, fps=VIDEO_FPS):\n",
    "    \"\"\"Analyze video using Qwen3-VL-30B-A3B-Instruct-FP8 with vLLM.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the video file\n",
    "        video_name: Name of the video file\n",
    "        fps: Target frames per second for video processing (default: 2.0)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load transcript if available\n",
    "    transcript_text = load_transcript(video_name)\n",
    "    \n",
    "    # Prepare transcript information for the prompt\n",
    "    if transcript_text:\n",
    "        transcript_info = f\"TRANSCRIPT:\\n{transcript_text}\\n\\n\"\n",
    "        print(f\"    ✓ Using transcript ({len(transcript_text)} characters)\")\n",
    "    else:\n",
    "        transcript_info = \"TRANSCRIPT: No transcript available for this video.\\n\\n\"\n",
    "        print(f\"    ⚠ No transcript found - proceeding without transcript\")\n",
    "    \n",
    "    # Format the comprehensive prompt with transcript\n",
    "    full_prompt = comprehensive_prompt.format(transcript_info=transcript_info)\n",
    "    \n",
    "    print(f\"    Prompt length: {len(full_prompt)} characters\")\n",
    "    print(f\"    Video FPS setting: {fps}\")\n",
    "    \n",
    "    # Prepare messages for Qwen3-VL model with FPS control\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"video\",\n",
    "                    \"video\": video_path,\n",
    "                    \"fps\": fps  # Set FPS to 2.0 for better frame sampling\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": full_prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Prepare inputs for vLLM\n",
    "    inputs = prepare_inputs_for_vllm(messages, processor)\n",
    "    \n",
    "    # Generate response using vLLM\n",
    "    outputs = llm.generate([inputs], SAMPLING_PARAMS)\n",
    "    response = outputs[0].outputs[0].text.strip()\n",
    "    \n",
    "    return response, transcript_text\n",
    "\n",
    "print(\"✓ Qwen3-VL-30B analysis function ready with vLLM, FPS=2.0, and high resolution!\")\n",
    "print(\"✓ FP8 quantized for efficient inference with near-BF16 performance\")\n",
    "print(\"✓ Enhanced celebrity recognition with 30B parameter model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e28b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all videos with Qwen3-VL-30B model\n",
    "if not os.path.exists(video_folder):\n",
    "    print(f\"Folder not found: {video_folder}\")\n",
    "else:\n",
    "    # Check if transcript folder exists\n",
    "    if not os.path.exists(transcript_folder):\n",
    "        print(f\"Warning: Transcript folder not found: {transcript_folder}\")\n",
    "        print(\"Will proceed without transcripts\")\n",
    "    else:\n",
    "        transcript_files = [f for f in os.listdir(transcript_folder) if f.endswith('.txt')]\n",
    "        print(f\"Found {len(transcript_files)} transcript files\")\n",
    "    \n",
    "    # Find video files\n",
    "    videos = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    print(f\"Found {len(videos)} videos\")\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Process each video\n",
    "    for i, video_file in enumerate(videos, 1):\n",
    "        print(f\"\\n[{i}/{len(videos)}] Processing with Qwen3-VL-30B-FP8: {video_file}\")\n",
    "        video_path = os.path.join(video_folder, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        \n",
    "        try:\n",
    "            # Analyze with Qwen3-VL-30B model\n",
    "            response, transcript_used = analyze_video_with_qwen3vl(video_path, video_file)\n",
    "            \n",
    "            # Prepare results\n",
    "            results = {\n",
    "                \"video\": video_file,\n",
    "                \"model\": \"Qwen3-VL-30B-A3B-Instruct-FP8\",\n",
    "                \"inference_engine\": \"vLLM\",\n",
    "                \"fps\": VIDEO_FPS,\n",
    "                \"resolution_settings\": {\n",
    "                    \"min_pixels\": 512 * 28 * 28,\n",
    "                    \"max_pixels\": 2048 * 28 * 28\n",
    "                },\n",
    "                \"sampling_params\": {\n",
    "                    \"temperature\": SAMPLING_PARAMS.temperature,\n",
    "                    \"max_tokens\": SAMPLING_PARAMS.max_tokens,\n",
    "                    \"top_k\": SAMPLING_PARAMS.top_k,\n",
    "                    \"top_p\": SAMPLING_PARAMS.top_p\n",
    "                },\n",
    "                \"transcript_available\": transcript_used is not None,\n",
    "                \"transcript_text\": transcript_used,\n",
    "                \"comprehensive_analysis\": {\n",
    "                    \"prompt\": comprehensive_prompt,\n",
    "                    \"response\": response\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Save results as JSON\n",
    "            json_file = os.path.join(output_folder, f\"{video_name}_qwen3vl30b_analysis.json\")\n",
    "            with open(json_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            # Save results as formatted text\n",
    "            txt_file = os.path.join(output_folder, f\"{video_name}_qwen3vl30b_analysis.txt\")\n",
    "            with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"VIDEO ANALYSIS: {video_file}\\n\")\n",
    "                f.write(f\"MODEL: Qwen3-VL-30B-A3B-Instruct-FP8\\n\")\n",
    "                f.write(f\"INFERENCE ENGINE: vLLM\\n\")\n",
    "                f.write(f\"FPS: {VIDEO_FPS}\\n\")\n",
    "                f.write(f\"RESOLUTION: min={512 * 28 * 28}, max={2048 * 28 * 28}\\n\")\n",
    "                f.write(f\"TEMPERATURE: {SAMPLING_PARAMS.temperature}, TOP_K: {SAMPLING_PARAMS.top_k}, TOP_P: {SAMPLING_PARAMS.top_p}\\n\")\n",
    "                f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "                \n",
    "                if transcript_used:\n",
    "                    f.write(\"TRANSCRIPT USED:\\n\")\n",
    "                    f.write(\"-\" * 20 + \"\\n\")\n",
    "                    f.write(f\"{transcript_used}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(\"TRANSCRIPT: Not available\\n\\n\")\n",
    "                \n",
    "                f.write(\"COMPREHENSIVE ANALYSIS:\\n\")\n",
    "                f.write(\"-\" * 25 + \"\\n\")\n",
    "                f.write(f\"{response}\\n\\n\")\n",
    "                \n",
    "                f.write(\"ANALYSIS PROMPT USED:\\n\")\n",
    "                f.write(\"-\" * 22 + \"\\n\")\n",
    "                f.write(comprehensive_prompt.format(transcript_info=\"[Transcript was inserted here if available]\"))\n",
    "            \n",
    "            print(f\"  ✓ Analysis completed successfully\")\n",
    "            print(f\"  ✓ Saved: {video_name}_qwen3vl30b_analysis.json and {video_name}_qwen3vl30b_analysis.txt\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {video_file}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Save error results\n",
    "            error_results = {\n",
    "                \"video\": video_file,\n",
    "                \"model\": \"Qwen3-VL-30B-A3B-Instruct-FP8\",\n",
    "                \"error\": str(e),\n",
    "                \"transcript_available\": False\n",
    "            }\n",
    "            \n",
    "            error_file = os.path.join(output_folder, f\"{video_name}_error.json\")\n",
    "            with open(error_file, 'w') as f:\n",
    "                json.dump(error_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✓ Done! Results saved to: {output_folder}\")\n",
    "    print(\"✓ Qwen3-VL-30B-A3B-Instruct-FP8 analysis complete\")\n",
    "    print(\"✓ Features: FP8 quantization, vLLM acceleration, superior celebrity recognition\")\n",
    "    print(\"✓ 30B parameters provide enhanced visual understanding and reasoning\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
