{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b04c1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install compatible torchvision for CUDA 12.x (12.4 detected)\n",
    "# Using PyTorch 2.5.1 which is more stable with torchvision\n",
    "# !pip install --upgrade --force-reinstall torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "891403d5-8eb4-4ec8-90df-9f084460021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We suggest you to set `dtype=torch.float16` for better efficiency on CUDA/XPU with AWQ.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7322980108c46eb8b4efef9eecf85db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe83992d5d4495cb5459f9de8a73780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b516400baf06462f9814dac3fd8a9f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWQ Model loaded!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# Load AWQ quantized model\n",
    "# Note: Using \"auto\" for torch_dtype as recommended in the documentation\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct-AWQ\", \n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Optional: Enable flash_attention_2 for better performance\n",
    "# Uncomment the following if you have flash_attention_2 installed:\n",
    "# model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2.5-VL-7B-Instruct-AWQ\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct-AWQ\")\n",
    "\n",
    "# Optional: Set custom min_pixels and max_pixels for performance tuning\n",
    "# Uncomment and adjust as needed:\n",
    "# min_pixels = 256 * 28 * 28\n",
    "# max_pixels = 1280 * 28 * 28\n",
    "# processor = AutoProcessor.from_pretrained(\n",
    "#     \"Qwen/Qwen2.5-VL-7B-Instruct-AWQ\", \n",
    "#     min_pixels=min_pixels, \n",
    "#     max_pixels=max_pixels\n",
    "# )\n",
    "\n",
    "print(\"AWQ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4708567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "video_folder = \"raw_videos\"  # UPDATE THIS\n",
    "transcript_folder = \"transcript_from_audio\"  # Transcripts are inside video folder\n",
    "output_folder = \"results\"\n",
    "\n",
    "# Single comprehensive prompt that asks all questions at once\n",
    "comprehensive_prompt = \"\"\"Analyze this video and transcript to answer each question specifically and directly.\n",
    "\n",
    "**ANALYSIS TASKS:**\n",
    "\n",
    "1. CELEBRITIES\n",
    "List any celebrities or public figures visible. Format: [Name] - [context/role in video]\n",
    "If none, respond: \"None identified\"\n",
    "\n",
    "2. PEOPLE COUNT\n",
    "Exact number of distinct individuals visible in video: [NUMBER]\n",
    "If crowd/unclear, provide: [approximate range] (e.g., \"~15-20 people\")\n",
    "\n",
    "3. GENDER\n",
    "List each person's apparent gender presentation:\n",
    "Person 1: [Male/Female/Not clearly visible]\n",
    "Person 2: [Male/Female/Not clearly visible]\n",
    "Format: [Person number/identifier]: [Gender]\n",
    "\n",
    "4. ETHNICITY\n",
    "Describe observed ethnic/racial characteristics per person:\n",
    "Person 1: [Specific observable characteristics - e.g., \"Light skin tone, blonde hair\" OR \"Dark skin tone\" OR \"East Asian appearance\"]\n",
    "Person 2: [Observable characteristics]\n",
    "Use descriptive physical traits, not demographic labels.\n",
    "\n",
    "5. ACTIVITIES\n",
    "List all visible activities/sports:\n",
    "- [Activity 1]: [brief description]\n",
    "- [Activity 2]: [brief description]\n",
    "Include location/setting context.\n",
    "\n",
    "6. TRANSCRIPT ANALYSIS\n",
    "Main topics discussed (if transcript available):\n",
    "- Topic 1: [specific detail]\n",
    "- Topic 2: [specific detail]\n",
    "- Topic 3: [specific detail]\n",
    "Key speakers (if identifiable): [names or descriptions]\n",
    "If no transcript: \"No transcript available\"\n",
    "\n",
    "**TRANSCRIPT PROVIDED:**\n",
    "{transcript_info}\n",
    "\n",
    "**RESPONSE INSTRUCTIONS:**\n",
    "- Answer only what you observe\n",
    "- Be specific, not vague\n",
    "- Use exact numbers where possible\n",
    "- Describe visible characteristics objectively\n",
    "- Do not speculate\n",
    "- Label each answer with its number\"\"\"\n",
    "\n",
    "print(f\"Video folder: {video_folder}\")\n",
    "print(f\"Transcript folder: {transcript_folder}\")\n",
    "print(\"Using single comprehensive prompt for all analyses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5437dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check transcript files availability\n",
    "print(\"=== TRANSCRIPT FOLDER DEBUG ===\")\n",
    "print(f\"Expected transcript folder path: {transcript_folder}\")\n",
    "if os.path.exists(transcript_folder):\n",
    "    transcript_files = [f for f in os.listdir(transcript_folder) if f.endswith('.txt')]\n",
    "    print(f\"✓ Transcript folder exists: {transcript_folder}\")\n",
    "    print(f\"Found {len(transcript_files)} .txt files:\")\n",
    "    for i, file in enumerate(transcript_files, 1):\n",
    "        file_path = os.path.join(transcript_folder, file)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "            print(f\"  {i}. {file} ({len(content)} characters)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {i}. {file} (Error reading: {e})\")\n",
    "else:\n",
    "    print(f\"Transcript folder does not exist: {transcript_folder}\")\n",
    "    print(\"Creating the folder...\")\n",
    "    os.makedirs(transcript_folder, exist_ok=True)\n",
    "    print(f\"✓ Created folder: {transcript_folder}\")\n",
    "    print(\"Please add your transcript .txt files to this folder!\")\n",
    "\n",
    "print(\"\\n=== VIDEO FOLDER DEBUG ===\")\n",
    "if os.path.exists(video_folder):\n",
    "    video_files = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    print(f\"✓ Video folder exists: {video_folder}\")\n",
    "    print(f\"Found {len(video_files)} video files:\")\n",
    "    for i, file in enumerate(video_files, 1):\n",
    "        print(f\"  {i}. {file}\")\n",
    "else:\n",
    "    print(f\"Video folder does not exist: {video_folder}\")\n",
    "    print(\"Please update the video_folder path in the settings above!\")\n",
    "\n",
    "print(\"\\n=== EXPECTED TRANSCRIPT NAMING ===\")\n",
    "print(\"Based on your example: 24717902_TV_Excuse_for_Running_audio_transcript.txt\")\n",
    "if 'video_files' in locals() and video_files:\n",
    "    for video_file in video_files[:3]:  # Show first 3 as examples\n",
    "        video_base = os.path.splitext(video_file)[0]\n",
    "        print(f\"For video '{video_file}', looking for transcripts:\")\n",
    "        print(f\"  - {video_base}_audio_transcript.txt  <- Most likely match\")\n",
    "        print(f\"  - {video_file}_transcript.txt\")\n",
    "        print(f\"  - {video_base}_transcript.txt\")\n",
    "        print(f\"  - {video_base}.txt\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"Example patterns that will be searched:\")\n",
    "    print(\"  - {video_name_without_ext}_audio_transcript.txt\")\n",
    "    print(\"  - {video_name}_transcript.txt\") \n",
    "    print(\"  - {video_name_without_ext}_transcript.txt\")\n",
    "    print(\"  - Plus fuzzy matching for partial name matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f61aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load transcript for a video\n",
    "def load_transcript(video_name):\n",
    "    \"\"\"Load transcript file if it exists for the given video name.\"\"\"\n",
    "    print(f\"    Looking for transcript for video: {video_name}\")\n",
    "    \n",
    "    # Extract base name without extension for matching\n",
    "    video_base = os.path.splitext(video_name)[0]\n",
    "    \n",
    "    # Try different possible transcript filename patterns\n",
    "    # Based on the example: 24717902_TV_Excuse_for_Running_audio_transcript.txt\n",
    "    possible_names = [\n",
    "        f\"{video_base}_audio_transcript.txt\",  # Most likely pattern\n",
    "        f\"{video_name}_transcript.txt\",\n",
    "        f\"{video_base}_transcript.txt\",\n",
    "        f\"{video_name}.txt\",\n",
    "        f\"{video_base}.txt\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"    Checking transcript folder: {transcript_folder}\")\n",
    "    print(f\"    Video base name: {video_base}\")\n",
    "    print(f\"    Possible transcript names: {possible_names}\")\n",
    "    \n",
    "    # List all files in transcript folder for debugging\n",
    "    if os.path.exists(transcript_folder):\n",
    "        all_transcript_files = os.listdir(transcript_folder)\n",
    "        print(f\"    Files in transcript folder: {all_transcript_files}\")\n",
    "        \n",
    "        # Also try fuzzy matching - look for files that contain the video base name\n",
    "        fuzzy_matches = [f for f in all_transcript_files if video_base in f and f.endswith('.txt')]\n",
    "        if fuzzy_matches:\n",
    "            print(f\"    Fuzzy matches found: {fuzzy_matches}\")\n",
    "            # Use the first fuzzy match if exact matches fail\n",
    "            possible_names.extend(fuzzy_matches)\n",
    "    else:\n",
    "        print(f\"    Transcript folder does not exist: {transcript_folder}\")\n",
    "        return None\n",
    "    \n",
    "    for transcript_name in possible_names:\n",
    "        transcript_path = os.path.join(transcript_folder, transcript_name)\n",
    "        print(f\"    Trying: {transcript_path}\")\n",
    "        if os.path.exists(transcript_path):\n",
    "            try:\n",
    "                with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read().strip()\n",
    "                print(f\"    ✓ Successfully loaded transcript: {transcript_name}\")\n",
    "                return content\n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Could not read transcript {transcript_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"    ✗ File not found: {transcript_name}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Enhanced analysis function with transcript integration\n",
    "def analyze_video_with_transcript(video_path, video_name):\n",
    "    \"\"\"Analyze video with integrated transcript information.\"\"\"\n",
    "    \n",
    "    # Load transcript if available\n",
    "    transcript_text = load_transcript(video_name)\n",
    "    \n",
    "    # Prepare transcript information for the prompt\n",
    "    if transcript_text:\n",
    "        transcript_info = f\"TRANSCRIPT:\\n{transcript_text}\\n\\n\"\n",
    "        print(f\"    ✓ Using transcript ({len(transcript_text)} characters)\")\n",
    "    else:\n",
    "        transcript_info = \"TRANSCRIPT: No transcript available for this video.\\n\\n\"\n",
    "        print(f\"    ⚠ No transcript found - proceeding without transcript\")\n",
    "    \n",
    "    # Format the comprehensive prompt with transcript\n",
    "    full_prompt = comprehensive_prompt.format(transcript_info=transcript_info)\n",
    "    \n",
    "    # Debug: show the actual prompt being used\n",
    "    print(f\"    Prompt length: {len(full_prompt)} characters\")\n",
    "    \n",
    "    # Prepare messages for the model\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"video\", \"video\": video_path},\n",
    "            {\"type\": \"text\", \"text\": full_prompt}\n",
    "        ]\n",
    "    }]\n",
    "    \n",
    "    # Process with the model\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=512)  # Increased tokens for comprehensive response\n",
    "    generated_ids_trimmed = [out[len(inp):] for inp, out in zip(inputs.input_ids, generated_ids)]\n",
    "    response = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True)[0].strip()\n",
    "    \n",
    "    return response, transcript_text\n",
    "\n",
    "print(\"Enhanced analysis function with correct transcript path structure ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2cf81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process all videos with transcript integration\n",
    "if not os.path.exists(video_folder):\n",
    "    print(f\"Folder not found: {video_folder}\")\n",
    "else:\n",
    "    # Check if transcript folder exists\n",
    "    if not os.path.exists(transcript_folder):\n",
    "        print(f\"Warning: Transcript folder not found: {transcript_folder}\")\n",
    "        print(\"Will proceed without transcripts\")\n",
    "    else:\n",
    "        transcript_files = [f for f in os.listdir(transcript_folder) if f.endswith('.txt')]\n",
    "        print(f\"Found {len(transcript_files)} transcript files\")\n",
    "    \n",
    "    # Find video files\n",
    "    videos = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    print(f\"Found {len(videos)} videos\")\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Process each video\n",
    "    for i, video_file in enumerate(videos, 1):\n",
    "        print(f\"\\n[{i}/{len(videos)}] Processing: {video_file}\")\n",
    "        video_path = os.path.join(video_folder, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        \n",
    "        try:\n",
    "            # Analyze with comprehensive prompt and transcript\n",
    "            response, transcript_used = analyze_video_with_transcript(video_path, video_file)\n",
    "            \n",
    "            # Prepare results\n",
    "            results = {\n",
    "                \"video\": video_file,\n",
    "                \"transcript_available\": transcript_used is not None,\n",
    "                \"transcript_text\": transcript_used,\n",
    "                \"comprehensive_analysis\": {\n",
    "                    \"prompt\": comprehensive_prompt,\n",
    "                    \"response\": response\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Save results as JSON\n",
    "            json_file = os.path.join(output_folder, f\"{video_name}_analysis.json\")\n",
    "            with open(json_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            # Save results as formatted text\n",
    "            txt_file = os.path.join(output_folder, f\"{video_name}_analysis.txt\")\n",
    "            with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"VIDEO ANALYSIS: {video_file}\\n\")\n",
    "                f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "                \n",
    "                if transcript_used:\n",
    "                    f.write(\"TRANSCRIPT USED:\\n\")\n",
    "                    f.write(\"-\" * 20 + \"\\n\")\n",
    "                    f.write(f\"{transcript_used}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(\"TRANSCRIPT: Not available\\n\\n\")\n",
    "                \n",
    "                f.write(\"COMPREHENSIVE ANALYSIS:\\n\")\n",
    "                f.write(\"-\" * 25 + \"\\n\")\n",
    "                f.write(f\"{response}\\n\\n\")\n",
    "                \n",
    "                f.write(\"ANALYSIS PROMPT USED:\\n\")\n",
    "                f.write(\"-\" * 22 + \"\\n\")\n",
    "                f.write(comprehensive_prompt.format(transcript_info=\"[Transcript was inserted here if available]\"))\n",
    "            \n",
    "            print(f\"  ✓ Analysis completed successfully\")\n",
    "            print(f\"  ✓ Saved: {video_name}_analysis.json and {video_name}_analysis.txt\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {video_file}: {str(e)}\")\n",
    "            \n",
    "            # Save error results\n",
    "            error_results = {\n",
    "                \"video\": video_file,\n",
    "                \"error\": str(e),\n",
    "                \"transcript_available\": False\n",
    "            }\n",
    "            \n",
    "            error_file = os.path.join(output_folder, f\"{video_name}_error.json\")\n",
    "            with open(error_file, 'w') as f:\n",
    "                json.dump(error_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nDone! Results saved to: {output_folder}\")\n",
    "    print(\"Each video now has comprehensive analysis with integrated transcript data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
