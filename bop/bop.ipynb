{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e748607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: IMPORTS\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel, WhiteKernel\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a950c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: CONFIGURATION - MODIFY THESE\n",
    "# =============================================================================\n",
    "\n",
    "FILE_PATH = \"your_data.xlsx\"           # <-- Your Excel file\n",
    "RESPONSE_COLUMN = \"yield\"              # <-- Your response variable name  \n",
    "EXCLUDE_COLUMNS = [\"experiment_id\"]    # <-- Columns to exclude from features\n",
    "TEST_SIZE = 0.2\n",
    "TOP_K = 5\n",
    "\n",
    "print(f\"Response: {RESPONSE_COLUMN}\")\n",
    "print(f\"Exclude: {EXCLUDE_COLUMNS}\")\n",
    "print(f\"Top K: {TOP_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a92af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: LOAD DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Try loading your file, or create sample data for demo\n",
    "try:\n",
    "    df = pd.read_excel(FILE_PATH)\n",
    "    print(f\"✓ Loaded: {df.shape}\")\n",
    "except:\n",
    "    print(\"Creating sample chemical data...\")\n",
    "    np.random.seed(42)\n",
    "    n = 200\n",
    "    df = pd.DataFrame({\n",
    "        'experiment_id': range(1, n+1),\n",
    "        'temperature_C': np.random.uniform(20, 100, n),\n",
    "        'pressure_bar': np.random.uniform(1, 10, n),\n",
    "        'pH': np.random.uniform(2, 12, n),\n",
    "        'concentration_mol_L': np.random.exponential(0.5, n),\n",
    "        'reaction_time_min': np.random.uniform(5, 120, n),\n",
    "        'catalyst_amount_g': np.random.uniform(0.1, 5, n),\n",
    "        'stirring_speed_rpm': np.random.uniform(100, 1000, n),\n",
    "        'solvent_ratio': np.random.uniform(0.1, 0.9, n),\n",
    "        'humidity_percent': np.random.uniform(30, 80, n),\n",
    "        'particle_size_um': np.random.uniform(1, 100, n),\n",
    "    })\n",
    "    # Response with known relationships\n",
    "    df['yield'] = (\n",
    "        0.5 * df['temperature_C'] +\n",
    "        2.0 * df['catalyst_amount_g'] +\n",
    "        -0.3 * df['pH'] +\n",
    "        0.1 * df['reaction_time_min'] +\n",
    "        np.random.normal(0, 5, n)\n",
    "    ).clip(0, 100)\n",
    "    \n",
    "    # Add some missing values\n",
    "    df.loc[np.random.choice(n, 5), 'humidity_percent'] = np.nan\n",
    "    print(f\"✓ Sample data created: {df.shape}\")\n",
    "\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: PREPARE FEATURES AND TARGET\n",
    "# =============================================================================\n",
    "\n",
    "# Get numeric columns only, exclude specified columns and response\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c not in EXCLUDE_COLUMNS + [RESPONSE_COLUMN]]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[RESPONSE_COLUMN].copy()\n",
    "\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols}\")\n",
    "print(f\"Target: {RESPONSE_COLUMN}\")\n",
    "print(f\"Shape: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: CHEMICAL DATA CHECKS\n",
    "# =============================================================================\n",
    "\n",
    "# Check for outliers (Z-score > 3)\n",
    "print(\"=\" * 50)\n",
    "print(\"OUTLIER DETECTION (Z-score > 3)\")\n",
    "print(\"=\" * 50)\n",
    "z_scores = np.abs((X - X.mean()) / X.std())\n",
    "outliers = (z_scores > 3).sum()\n",
    "for col in outliers[outliers > 0].index:\n",
    "    print(f\"  {col}: {outliers[col]} outliers\")\n",
    "if outliers.sum() == 0:\n",
    "    print(\"  No outliers detected\")\n",
    "\n",
    "# Check multicollinearity\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MULTICOLLINEARITY CHECK (|r| > 0.9)\")\n",
    "print(\"=\" * 50)\n",
    "corr = X.corr().abs()\n",
    "high_corr = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        if corr.iloc[i, j] > 0.9:\n",
    "            high_corr.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
    "            print(f\"  {corr.columns[i]} ↔ {corr.columns[j]}: {corr.iloc[i,j]:.3f}\")\n",
    "if not high_corr:\n",
    "    print(\"  No highly correlated features\")\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X.corr(), annot=True, cmap='RdBu_r', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8276710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: TRAIN/TEST SPLIT (BEFORE STANDARDIZATION - NO LEAKAGE)\n",
    "# =============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: IMPUTE MISSING VALUES (FIT ON TRAIN ONLY)\n",
    "# =============================================================================\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Fit on train, transform both\n",
    "X_train = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    imputer.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Handle missing in y\n",
    "train_mask = ~y_train.isnull()\n",
    "test_mask = ~y_test.isnull()\n",
    "X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "\n",
    "print(f\"✓ Missing values imputed (fitted on training only)\")\n",
    "print(f\"  Final training: {len(X_train)}, test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: STANDARDIZATION (FIT ON TRAIN ONLY - NO LEAKAGE)\n",
    "# =============================================================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data ONLY\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Apply training statistics to test data\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(\"✓ Standardization complete (NO DATA LEAKAGE)\")\n",
    "print(\"  - Scaler fitted on training data only\")\n",
    "print(\"  - Training mean applied to test data\")\n",
    "print(f\"\\nTraining data stats (should be ~0 mean, ~1 std):\")\n",
    "print(X_train_scaled.describe().loc[['mean', 'std']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90edc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: METHOD 1 - LINEAR REGRESSION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 1: LINEAR REGRESSION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Coefficients as importance (absolute value for standardized data)\n",
    "lr_importance = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'coefficient': lr_model.coef_,\n",
    "    'importance': np.abs(lr_model.coef_)\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "lr_importance['rank'] = range(1, len(lr_importance) + 1)\n",
    "\n",
    "# Performance\n",
    "lr_train_r2 = r2_score(y_train, lr_model.predict(X_train_scaled))\n",
    "lr_test_r2 = r2_score(y_test, lr_model.predict(X_test_scaled))\n",
    "\n",
    "print(f\"\\nTrain R²: {lr_train_r2:.4f}\")\n",
    "print(f\"Test R²:  {lr_test_r2:.4f}\")\n",
    "print(f\"\\nFeature Importance (|coefficient|):\")\n",
    "print(lr_importance[['rank', 'feature', 'coefficient', 'importance']].to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if c > 0 else 'red' for c in lr_importance['coefficient']]\n",
    "plt.barh(lr_importance['feature'][::-1], lr_importance['importance'][::-1], color=colors[::-1])\n",
    "plt.xlabel('|Coefficient|')\n",
    "plt.title('Linear Regression Feature Importance\\n(Green=Positive, Red=Negative)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: METHOD 2 - RANDOM FOREST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 2: RANDOM FOREST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Built-in feature importance (MDI)\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance_mdi': rf_model.feature_importances_\n",
    "}).sort_values('importance_mdi', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Permutation importance (more reliable)\n",
    "print(\"\\nCalculating permutation importance...\")\n",
    "perm_result = permutation_importance(\n",
    "    rf_model, X_test_scaled, y_test,\n",
    "    n_repeats=30, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "rf_importance['importance_perm'] = [\n",
    "    perm_result.importances_mean[list(X_train_scaled.columns).index(f)] \n",
    "    for f in rf_importance['feature']\n",
    "]\n",
    "rf_importance['rank'] = range(1, len(rf_importance) + 1)\n",
    "\n",
    "# Performance\n",
    "rf_train_r2 = r2_score(y_train, rf_model.predict(X_train_scaled))\n",
    "rf_test_r2 = r2_score(y_test, rf_model.predict(X_test_scaled))\n",
    "\n",
    "print(f\"\\nTrain R²: {rf_train_r2:.4f}\")\n",
    "print(f\"Test R²:  {rf_test_r2:.4f}\")\n",
    "print(f\"\\nFeature Importance:\")\n",
    "print(rf_importance[['rank', 'feature', 'importance_mdi', 'importance_perm']].to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].barh(rf_importance['feature'][::-1], rf_importance['importance_mdi'][::-1], color='forestgreen')\n",
    "axes[0].set_xlabel('Importance (MDI)')\n",
    "axes[0].set_title('Random Forest - Mean Decrease Impurity')\n",
    "\n",
    "rf_perm_sorted = rf_importance.sort_values('importance_perm', ascending=False)\n",
    "axes[1].barh(rf_perm_sorted['feature'][::-1], rf_perm_sorted['importance_perm'][::-1], color='steelblue')\n",
    "axes[1].set_xlabel('Importance (Permutation)')\n",
    "axes[1].set_title('Random Forest - Permutation Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: METHOD 3 - GAUSSIAN PROCESS (BAYESIAN)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 3: GAUSSIAN PROCESS (BAYESIAN)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Subsample if needed (GP is O(n³))\n",
    "max_samples = 500\n",
    "if len(X_train_scaled) > max_samples:\n",
    "    print(f\"Subsampling to {max_samples} for GP (computational efficiency)\")\n",
    "    idx = np.random.choice(len(X_train_scaled), max_samples, replace=False)\n",
    "    X_train_gp = X_train_scaled.iloc[idx]\n",
    "    y_train_gp = y_train.iloc[idx]\n",
    "else:\n",
    "    X_train_gp = X_train_scaled\n",
    "    y_train_gp = y_train\n",
    "\n",
    "# Kernel with ARD\n",
    "n_features = X_train_scaled.shape[1]\n",
    "kernel = ConstantKernel(1.0) * Matern(length_scale=np.ones(n_features), nu=2.5) + WhiteKernel(1.0)\n",
    "\n",
    "print(\"Fitting Gaussian Process (may take a moment)...\")\n",
    "gp_model = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_model.fit(X_train_gp, y_train_gp)\n",
    "\n",
    "# Permutation importance\n",
    "print(\"Calculating permutation importance...\")\n",
    "gp_perm = permutation_importance(\n",
    "    gp_model, X_test_scaled, y_test,\n",
    "    n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "\n",
    "gp_importance = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance': gp_perm.importances_mean,\n",
    "    'importance_std': gp_perm.importances_std\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "gp_importance['rank'] = range(1, len(gp_importance) + 1)\n",
    "\n",
    "# Performance\n",
    "gp_train_r2 = r2_score(y_train_gp, gp_model.predict(X_train_gp))\n",
    "gp_test_r2 = r2_score(y_test, gp_model.predict(X_test_scaled))\n",
    "\n",
    "print(f\"\\nTrain R²: {gp_train_r2:.4f}\")\n",
    "print(f\"Test R²:  {gp_test_r2:.4f}\")\n",
    "print(f\"\\nFeature Importance (Permutation):\")\n",
    "print(gp_importance[['rank', 'feature', 'importance', 'importance_std']].to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(gp_importance['feature'][::-1], gp_importance['importance'][::-1], \n",
    "         xerr=gp_importance['importance_std'][::-1], color='darkorange', capsize=3)\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.title('Gaussian Process - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caab150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: AGGREGATE RANKINGS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"AGGREGATED RANKINGS (ALL 3 METHODS)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create ranking from each method\n",
    "lr_ranking = lr_importance[['feature']].copy()\n",
    "lr_ranking['rank_lr'] = range(1, len(lr_ranking) + 1)\n",
    "\n",
    "rf_ranking = rf_importance[['feature']].copy()\n",
    "rf_ranking['rank_rf'] = range(1, len(rf_ranking) + 1)\n",
    "\n",
    "gp_ranking = gp_importance[['feature']].copy()\n",
    "gp_ranking['rank_gp'] = range(1, len(gp_ranking) + 1)\n",
    "\n",
    "# Merge\n",
    "combined = lr_ranking.merge(rf_ranking, on='feature').merge(gp_ranking, on='feature')\n",
    "\n",
    "# Average rank (lower = more important)\n",
    "combined['avg_rank'] = combined[['rank_lr', 'rank_rf', 'rank_gp']].mean(axis=1)\n",
    "combined = combined.sort_values('avg_rank').reset_index(drop=True)\n",
    "combined['final_rank'] = range(1, len(combined) + 1)\n",
    "\n",
    "print(\"\\nConsensus Ranking:\")\n",
    "print(combined[['final_rank', 'feature', 'rank_lr', 'rank_rf', 'rank_gp', 'avg_rank']].to_string(index=False))\n",
    "\n",
    "# Get top K\n",
    "top_k_features = combined.head(TOP_K)['feature'].tolist()\n",
    "print(f\"\\n✓ TOP {TOP_K} FEATURES: {top_k_features}\")\n",
    "\n",
    "# Store for later use\n",
    "consensus_ranking = combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ffda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: RANKING VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar comparison\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(combined.head(TOP_K)))\n",
    "width = 0.25\n",
    "\n",
    "ax1.bar(x - width, combined.head(TOP_K)['rank_lr'], width, label='Linear Reg', color='steelblue')\n",
    "ax1.bar(x, combined.head(TOP_K)['rank_rf'], width, label='Random Forest', color='forestgreen')\n",
    "ax1.bar(x + width, combined.head(TOP_K)['rank_gp'], width, label='Gaussian Process', color='darkorange')\n",
    "\n",
    "ax1.set_xlabel('Feature')\n",
    "ax1.set_ylabel('Rank (lower = better)')\n",
    "ax1.set_title('Ranking Comparison - Top Features')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(combined.head(TOP_K)['feature'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Heatmap\n",
    "ax2 = axes[1]\n",
    "heatmap_data = combined.set_index('feature')[['rank_lr', 'rank_rf', 'rank_gp']]\n",
    "heatmap_data.columns = ['Linear Reg', 'Random Forest', 'Gaussian Process']\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='RdYlGn_r', ax=ax2)\n",
    "ax2.set_title('Feature Rankings Heatmap\\n(Lower = More Important)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a570feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 14: MANUAL FEATURE SELECTION (FOR RESEARCHERS TO OVERRIDE)\n",
    "# =============================================================================\n",
    "\n",
    "def select_features(features_to_use):\n",
    "    \"\"\"\n",
    "    Manually select which features to use.\n",
    "    Call this function with your desired feature list.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    features_to_use : list\n",
    "        List of feature names to use\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    selected_features : list\n",
    "        Validated list of selected features\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    selected = select_features(['temperature_C', 'catalyst_amount_g', 'pH'])\n",
    "    \"\"\"\n",
    "    all_features = list(X_train_scaled.columns)\n",
    "    \n",
    "    # Validate\n",
    "    invalid = [f for f in features_to_use if f not in all_features]\n",
    "    valid = [f for f in features_to_use if f in all_features]\n",
    "    \n",
    "    if invalid:\n",
    "        print(f\"⚠ Invalid features (ignored): {invalid}\")\n",
    "    \n",
    "    print(f\"\\n✓ Selected {len(valid)} features:\")\n",
    "    for i, f in enumerate(valid, 1):\n",
    "        # Find ranks from each method\n",
    "        lr_rank = lr_importance[lr_importance['feature'] == f]['rank'].values[0]\n",
    "        rf_rank = rf_importance[rf_importance['feature'] == f]['rank'].values[0]\n",
    "        gp_rank = gp_importance[gp_importance['feature'] == f]['rank'].values[0]\n",
    "        print(f\"  {i}. {f} (LR:{lr_rank}, RF:{rf_rank}, GP:{gp_rank})\")\n",
    "    \n",
    "    return valid\n",
    "\n",
    "\n",
    "def show_all_features():\n",
    "    \"\"\"Display all available features with their rankings.\"\"\"\n",
    "    print(\"\\nALL AVAILABLE FEATURES:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'#':<4} {'Feature':<25} {'LR':<6} {'RF':<6} {'GP':<6} {'Avg':<6}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for _, row in consensus_ranking.iterrows():\n",
    "        print(f\"{int(row['final_rank']):<4} {row['feature']:<25} \"\n",
    "              f\"{int(row['rank_lr']):<6} {int(row['rank_rf']):<6} \"\n",
    "              f\"{int(row['rank_gp']):<6} {row['avg_rank']:<6.2f}\")\n",
    "\n",
    "\n",
    "def use_top_k(k):\n",
    "    \"\"\"Select top K features from consensus ranking.\"\"\"\n",
    "    features = consensus_ranking.head(k)['feature'].tolist()\n",
    "    print(f\"✓ Selected top {k} features: {features}\")\n",
    "    return features\n",
    "\n",
    "\n",
    "# Show options\n",
    "show_all_features()\n",
    "print(f\"\\nCurrent selection (top {TOP_K}): {top_k_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8847a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 15: EXAMPLE - OVERRIDE FEATURE SELECTION\n",
    "# =============================================================================\n",
    "\n",
    "# OPTION 1: Use top K from consensus\n",
    "selected_features = use_top_k(TOP_K)\n",
    "\n",
    "# OPTION 2: Manually select specific features (uncomment to use)\n",
    "# selected_features = select_features(['temperature_C', 'catalyst_amount_g', 'pH', 'reaction_time_min'])\n",
    "\n",
    "# OPTION 3: Select by examining rankings and choosing manually\n",
    "# show_all_features()  # Look at rankings\n",
    "# selected_features = select_features(['your', 'chosen', 'features'])\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"FINAL SELECTED FEATURES: {selected_features}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d641ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 16: FINAL MODEL WITH SELECTED FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "# Subset data to selected features\n",
    "X_train_final = X_train_scaled[selected_features]\n",
    "X_test_final = X_test_scaled[selected_features]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FINAL MODEL COMPARISON (Selected Features Only)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Features used: {selected_features}\\n\")\n",
    "\n",
    "# Linear Regression\n",
    "lr_final = LinearRegression()\n",
    "lr_final.fit(X_train_final, y_train)\n",
    "lr_r2 = r2_score(y_test, lr_final.predict(X_test_final))\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_final.predict(X_test_final)))\n",
    "\n",
    "# Random Forest\n",
    "rf_final = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_final.fit(X_train_final, y_train)\n",
    "rf_r2 = r2_score(y_test, rf_final.predict(X_test_final))\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_final.predict(X_test_final)))\n",
    "\n",
    "# Gaussian Process\n",
    "gp_kernel = ConstantKernel(1.0) * Matern(length_scale=np.ones(len(selected_features)), nu=2.5) + WhiteKernel(1.0)\n",
    "gp_final = GaussianProcessRegressor(kernel=gp_kernel, n_restarts_optimizer=5, random_state=RANDOM_STATE, normalize_y=True)\n",
    "gp_final.fit(X_train_final, y_train)\n",
    "gp_r2 = r2_score(y_test, gp_final.predict(X_test_final))\n",
    "gp_rmse = np.sqrt(mean_squared_error(y_test, gp_final.predict(X_test_final)))\n",
    "\n",
    "# Results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Gaussian Process'],\n",
    "    'Test R²': [lr_r2, rf_r2, gp_r2],\n",
    "    'Test RMSE': [lr_rmse, rf_rmse, gp_rmse]\n",
    "})\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Plot predictions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "models = [('Linear Regression', lr_final), ('Random Forest', rf_final), ('Gaussian Process', gp_final)]\n",
    "\n",
    "for ax, (name, model) in zip(axes, models):\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    ax.scatter(y_test, y_pred, alpha=0.6)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_title(f'{name}\\nR² = {r2_score(y_test, y_pred):.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87956822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 17: EXPORT RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "# Save rankings to CSV\n",
    "consensus_ranking.to_csv('feature_rankings.csv', index=False)\n",
    "print(\"✓ Saved: feature_rankings.csv\")\n",
    "\n",
    "# Save selected features\n",
    "with open('selected_features.txt', 'w') as f:\n",
    "    f.write('\\n'.join(selected_features))\n",
    "print(\"✓ Saved: selected_features.txt\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total features analyzed: {len(feature_cols)}\")\n",
    "print(f\"Selected features: {len(selected_features)}\")\n",
    "print(f\"Features: {selected_features}\")\n",
    "print(f\"Best model: {results.loc[results['Test R²'].idxmax(), 'Model']}\")\n",
    "print(f\"Best R²: {results['Test R²'].max():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
